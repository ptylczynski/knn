{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. K-NN classifier\n",
    "\n",
    "**Question** How does the k-nn algorithm work?\n",
    "\n",
    "**Question** What are the parameters we need to choose to classify with k-NN? How can we choose them\n",
    "\n",
    "**Question** What are the advantages and disadvantages of this algorithm? For which kind of dataset it would be appropriate and for which datasets it wouldn't?\n",
    "\n",
    "**Question** How can we deal with nominal values in distance measurement?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In further part of the laboratory, we will perform a preprocessing of the data and a classification of a set of biomedical voice measurements. Some of them has been recorded for people with Parkinson's desease.\n",
    "\n",
    "More about the dataset: https://archive.ics.uci.edu/ml/datasets/parkinsons\n",
    "\n",
    "First, we load the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data loading and analysis of the attributes\n",
    "Let's start with the data preparation, \n",
    "#### 2.1. Load the dataset from file parkinsons.csv into data frame using library pandas (pd.read_csv). Write the body of the read_data function to return a data frame with attributes and a list with class labels. Classes are available in 'status' column. You should also remove column 'name' from the data (see function drop of dataFrame https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    dx = df.drop(columns=['status'])\n",
    "    dx.drop(columns='name', inplace=True)\n",
    "    return dx, df.loc[:,'status']\n",
    "\n",
    "data_X, data_Y = read_data(\"parkinsons.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we have loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>MDVP:Shimmer(dB)</th>\n",
       "      <th>...</th>\n",
       "      <th>MDVP:APQ</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>0.426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02971</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>0.626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04368</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>0.482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03590</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>0.517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03772</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>0.584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04465</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  MDVP:Jitter(Abs)  \\\n",
       "0      119.992       157.302        74.997         0.00784           0.00007   \n",
       "1      122.400       148.650       113.819         0.00968           0.00008   \n",
       "2      116.682       131.111       111.555         0.01050           0.00009   \n",
       "3      116.676       137.871       111.366         0.00997           0.00009   \n",
       "4      116.014       141.781       110.655         0.01284           0.00011   \n",
       "\n",
       "   MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  MDVP:Shimmer(dB)  ...  \\\n",
       "0   0.00370   0.00554     0.01109       0.04374             0.426  ...   \n",
       "1   0.00465   0.00696     0.01394       0.06134             0.626  ...   \n",
       "2   0.00544   0.00781     0.01633       0.05233             0.482  ...   \n",
       "3   0.00502   0.00698     0.01505       0.05492             0.517  ...   \n",
       "4   0.00655   0.00908     0.01966       0.06425             0.584  ...   \n",
       "\n",
       "   MDVP:APQ  Shimmer:DDA      NHR     HNR      RPDE       DFA   spread1  \\\n",
       "0   0.02971      0.06545  0.02211  21.033  0.414783  0.815285 -4.813031   \n",
       "1   0.04368      0.09403  0.01929  19.085  0.458359  0.819521 -4.075192   \n",
       "2   0.03590      0.08270  0.01309  20.651  0.429895  0.825288 -4.443179   \n",
       "3   0.03772      0.08771  0.01353  20.644  0.434969  0.819235 -4.117501   \n",
       "4   0.04465      0.10470  0.01767  19.649  0.417356  0.823484 -3.747787   \n",
       "\n",
       "    spread2        D2       PPE  \n",
       "0  0.266482  2.301442  0.284654  \n",
       "1  0.335590  2.486855  0.368674  \n",
       "2  0.311173  2.342259  0.332634  \n",
       "3  0.334147  2.405554  0.368975  \n",
       "4  0.234513  2.332180  0.410335  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "5      1\n",
       "6      1\n",
       "7      1\n",
       "8      1\n",
       "9      1\n",
       "10     1\n",
       "11     1\n",
       "12     1\n",
       "13     1\n",
       "14     1\n",
       "15     1\n",
       "16     1\n",
       "17     1\n",
       "18     1\n",
       "19     1\n",
       "20     1\n",
       "21     1\n",
       "22     1\n",
       "23     1\n",
       "24     1\n",
       "25     1\n",
       "26     1\n",
       "27     1\n",
       "28     1\n",
       "29     1\n",
       "      ..\n",
       "165    0\n",
       "166    0\n",
       "167    0\n",
       "168    0\n",
       "169    0\n",
       "170    0\n",
       "171    0\n",
       "172    0\n",
       "173    0\n",
       "174    0\n",
       "175    0\n",
       "176    0\n",
       "177    1\n",
       "178    1\n",
       "179    1\n",
       "180    1\n",
       "181    1\n",
       "182    1\n",
       "183    0\n",
       "184    0\n",
       "185    0\n",
       "186    0\n",
       "187    0\n",
       "188    0\n",
       "189    0\n",
       "190    0\n",
       "191    0\n",
       "192    0\n",
       "193    0\n",
       "194    0\n",
       "Name: status, Length: 195, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Let's analyse the given data. \n",
    "* How many attributes are in given data?\n",
    "* Are the attributes on the common scale?\n",
    "* Are observations equally distributed for sick and healthy people?\n",
    "\n",
    "Plot the histogram of the assigned class and analyse the distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 48.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 147.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_X\n",
    "# plt.hist(data_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the histograms of the first 5 attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([12., 54., 20., 31., 17., 18., 21.,  8.,  9.,  5.]),\n",
       " array([ 88.333 , 105.5102, 122.6874, 139.8646, 157.0418, 174.219 ,\n",
       "        191.3962, 208.5734, 225.7506, 242.9278, 260.105 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data_X.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train and test set selection\n",
    "\n",
    "#### We want to build our classifier and test it on another set of observations.\n",
    "\n",
    "To split data into train and test sets use train_test_split method from sklearn.model_selection module (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). Use 80% of cases in train set and 20% in test set. \n",
    "Use random_state = 5 just to be sure we all have the same rows in train and test sets :)\n",
    "\n",
    "split_data should return a tuple containing: dataframe with train set attributes, list of labels for train data, dataframe with test set attributes and a list of labels for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows in train set:  156\n",
      "rows in test set: 39\n"
     ]
    }
   ],
   "source": [
    "def split_data(data_X, data_Y, test_percent = 20, random_state=5):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data_X, data_Y, test_size=test_percent / 100, random_state=random_state)\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "    \n",
    "(train_X, train_Y, test_X, test_Y) = split_data(data_X, data_Y)\n",
    "print(\"rows in train set: \", train_X.shape[0])\n",
    "print(\"rows in test set:\", test_X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data standarization/normalization\n",
    "#### 4.1. Use k-nn algorithm to classify the obtained test set using k=3. What is the accuracy of the classification?\n",
    "\n",
    "Use KNeighborsClassifier class from sklearn.neighbors module. Useful methods: fit and predict. Classification accuracy can be obtained with accuracy_score method from sklearn.metrics. Function get_classification_accuracy should return the accuracy of classification of given test set on model build with train set.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7692307692307693"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_classification_accuracy(train_data_X, train_data_Y, test_data_X, test_data_Y, k = 3):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "    neigh.fit(train_data_X, train_data_Y)\n",
    "    pred = neigh.predict(test_data_X)\n",
    "    return metrics.accuracy_score(test_data_Y, pred)\n",
    "\n",
    "get_classification_accuracy(train_X, train_Y, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Perform some normalization or standarization of attributes. Then repeat the classification. Do the classification accuracy change?\n",
    "\n",
    "You can use sklearn.preprocessing.StandardScaler, sklearn.preprocessing.MinMaxScaler or sklearn.preprocessing.MaxAbsScaler and their fit_transform/transform methods.\n",
    "\n",
    "Try other standarization methods to verify the standarization procedure influence the classification accuracy.\n",
    "standarize_train_and_test should return 2 dataFrames - with normalized train and normalized test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standarize_train_and_test(train_X, test_X):\n",
    "    #   TODO replace the following line with your code\n",
    "    return train_X, test_X\n",
    "\n",
    "norm_train_X, norm_test_X = standarize_train_and_test(train_X, test_X)\n",
    "get_classification_accuracy(norm_train_X, train_Y, norm_test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Choosing k value\n",
    "Using obtained in previous exercices train set with normalization/standarization use k-nn algoritm using k from 1 to 20. Use 5-fold cross-validation within the train set to obtain the classification accuracy. Plot the obtained accuracy of the classification. Which k value seems to be the best for the given dataset?\n",
    "\n",
    "See https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html for more info about cross validation in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Testing classifier\n",
    "Train the k-NN classifier again and test it using the obtained best k value on a test set to check the final classification accuracy. You can just call the previous written function get_classification_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# get_classification_accuracy(..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Homework\n",
    "You are given a dataset containing information about 1600 red wines (winequality.csv) containing 11 attributes and assignment to one of the three wine quality classess: \"poor\", \"medium\" and \"good\". Perform a preprocessing of this dataset (normalization, standardization). Divide this set into the train and test sets. Choose experimentally the best value of k (using cross-validation) and perform classification using the  k-nn algoritm with the chosen k value. Write a report containing information about the used preprocessing methods, chosen train/test split method (percentage of examples in train/test sets, if shuffling or stratification used), plot of the accuracy depending of k parameter, finally chosen k and obtained classification accuracy on a test set.\n",
    "\n",
    "**Deadline +2 weeks**\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}